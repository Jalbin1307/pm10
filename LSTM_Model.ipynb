{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "from ast import literal_eval\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = open('listfile.csv', 'r')\n",
    "# rdr = csv.reader(f)\n",
    "# pm = []\n",
    "# time = []\n",
    "# for line in rdr:\n",
    "#     pm.append(line)\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"last_lf_v.csv\", sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type 0</th>\n",
       "      <th>type 1</th>\n",
       "      <th>type 2</th>\n",
       "      <th>type 3</th>\n",
       "      <th>type 4</th>\n",
       "      <th>type 5</th>\n",
       "      <th>type 6</th>\n",
       "      <th>type 7</th>\n",
       "      <th>type 8</th>\n",
       "      <th>type 9</th>\n",
       "      <th>...</th>\n",
       "      <th>type 30</th>\n",
       "      <th>type 31</th>\n",
       "      <th>type 32</th>\n",
       "      <th>type 33</th>\n",
       "      <th>type 34</th>\n",
       "      <th>type 35</th>\n",
       "      <th>type 36</th>\n",
       "      <th>type 37</th>\n",
       "      <th>type 38</th>\n",
       "      <th>type 39</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>54</td>\n",
       "      <td>162</td>\n",
       "      <td>233</td>\n",
       "      <td>184</td>\n",
       "      <td>174</td>\n",
       "      <td>96</td>\n",
       "      <td>74</td>\n",
       "      <td>82</td>\n",
       "      <td>110</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>42</td>\n",
       "      <td>25</td>\n",
       "      <td>44</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>38</td>\n",
       "      <td>33</td>\n",
       "      <td>40</td>\n",
       "      <td>60</td>\n",
       "      <td>51</td>\n",
       "      <td>62</td>\n",
       "      <td>49</td>\n",
       "      <td>30</td>\n",
       "      <td>56</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>33</td>\n",
       "      <td>9</td>\n",
       "      <td>27</td>\n",
       "      <td>21</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>51</td>\n",
       "      <td>57</td>\n",
       "      <td>18</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>27</td>\n",
       "      <td>22</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>22</td>\n",
       "      <td>26</td>\n",
       "      <td>29</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "      <td>48</td>\n",
       "      <td>38</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>48</td>\n",
       "      <td>45</td>\n",
       "      <td>54</td>\n",
       "      <td>28</td>\n",
       "      <td>52</td>\n",
       "      <td>48</td>\n",
       "      <td>89</td>\n",
       "      <td>31</td>\n",
       "      <td>20</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   type 0  type 1  type 2  type 3  type 4  type 5  type 6  type 7  type 8  \\\n",
       "0       4       4       5       4       5       4       4       7      11   \n",
       "1       8       8      14      16      23      23      42      25      44   \n",
       "2       9      12      33       9      27      21       9      13      12   \n",
       "3       3       3       4       3       3       3       4       7      10   \n",
       "4      23       4      17      13      13      25       5       6      16   \n",
       "\n",
       "   type 9  ...  type 30  type 31  type 32  type 33  type 34  type 35  type 36  \\\n",
       "0       4  ...       54      162      233      184      174       96       74   \n",
       "1      21  ...       38       33       40       60       51       62       49   \n",
       "2      20  ...       51       57       18       15       14       27       22   \n",
       "3      15  ...       14       22       26       29        6       16       11   \n",
       "4      19  ...       48       45       54       28       52       48       89   \n",
       "\n",
       "   type 37  type 38  type 39  \n",
       "0       82      110       44  \n",
       "1       30       56       32  \n",
       "2       13        6       12  \n",
       "3       48       38       68  \n",
       "4       31       20       60  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n = len(pm[0])\n",
    "# a = []\n",
    "# for i in range(0, n):\n",
    "#     list = literal_eval(pm[0][i])\n",
    "#     a.append(list)\n",
    "# data = np.array(a)\n",
    "# for i in range(0,len(data)):\n",
    "#     print(i,\":\",len(data[i]))\n",
    "# data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b = []\n",
    "# for i in range(0, len(a)):\n",
    "#     b.append(a[i][30:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = []\n",
    "# for i in range(0, len(a)):\n",
    "#     x.append(a[i][:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "type = [\"type %d\"%i for i in range(data.shape[1]-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(data[type])\n",
    "y = np.array(data['type 39'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(79, 39)\n",
      "(79,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = np.array(data['type %d'%i for i in range(data.shape[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1         2         3         4         5         6   \\\n",
      "0   0.004348  0.000000  0.058824  0.015152  0.232558  0.053333  0.270833   \n",
      "1   0.004348  0.000000  0.117647  0.015152  0.011628  0.186667  0.375000   \n",
      "2   0.008696  0.111111  0.529412  0.030303  0.162791  0.360000  0.041667   \n",
      "3   0.004348  0.148148  0.058824  0.015152  0.116279  0.520000  0.104167   \n",
      "4   0.008696  0.277778  0.411765  0.015152  0.116279  0.373333  0.333333   \n",
      "5   0.004348  0.277778  0.294118  0.015152  0.255814  0.546667  0.000000   \n",
      "6   0.004348  0.629630  0.058824  0.030303  0.023256  0.040000  0.041667   \n",
      "7   0.017391  0.314815  0.137255  0.075758  0.034884  0.213333  0.041667   \n",
      "8   0.034783  0.666667  0.117647  0.121212  0.151163  0.253333  0.083333   \n",
      "9   0.004348  0.240741  0.274510  0.196970  0.186047  0.453333  0.562500   \n",
      "10  0.000000  0.018519  0.098039  0.030303  0.372093  0.573333  0.354167   \n",
      "11  0.034783  0.314815  0.509804  0.121212  0.151163  0.013333  0.062500   \n",
      "12  0.026087  0.740741  0.274510  0.075758  0.023256  0.386667  0.291667   \n",
      "13  0.021739  0.648148  0.372549  0.106061  0.081395  0.240000  0.291667   \n",
      "14  0.047826  0.351852  0.078431  0.030303  0.000000  0.253333  0.083333   \n",
      "15  0.139130  0.314815  0.392157  0.030303  0.034884  0.666667  0.062500   \n",
      "16  0.304348  0.703704  0.352941  0.060606  0.034884  0.213333  0.083333   \n",
      "17  0.286957  0.185185  0.372549  0.000000  0.209302  0.000000  0.104167   \n",
      "18  0.513043  0.277778  0.372549  0.060606  0.081395  0.146667  0.083333   \n",
      "19  0.552174  0.296296  0.333333  0.030303  0.279070  1.000000  0.166667   \n",
      "20  0.304348  0.388889  0.431373  0.090909  0.651163  0.040000  0.250000   \n",
      "21  0.273913  0.537037  0.215686  0.000000  0.825581  0.173333  0.645833   \n",
      "22  0.295652  0.148148  0.313725  0.075758  0.406977  0.120000  0.312500   \n",
      "23  0.286957  0.055556  0.078431  0.318182  0.523256  0.466667  0.104167   \n",
      "24  0.565217  0.981481  0.058824  0.030303  0.372093  0.146667  0.354167   \n",
      "25  0.400000  0.259259  0.254902  0.227273  0.755814  0.453333  0.354167   \n",
      "26  0.234783  0.518519  0.235294  0.166667  0.895349  0.026667  0.062500   \n",
      "27  0.243478  0.685185  0.529412  0.166667  0.441860  0.373333  0.500000   \n",
      "28  0.130435  0.462963  0.176471  0.242424  0.837209  0.026667  0.354167   \n",
      "29  0.308696  0.240741  0.294118  0.242424  0.441860  0.280000  0.333333   \n",
      "30  0.221739  0.555556  0.882353  0.181818  0.523256  0.400000  0.625000   \n",
      "31  0.691304  0.462963  1.000000  0.303030  0.488372  0.226667  0.125000   \n",
      "32  1.000000  0.592593  0.235294  0.363636  0.593023  0.400000  0.395833   \n",
      "33  0.786957  0.962963  0.176471  0.409091  0.290698  0.253333  0.375000   \n",
      "34  0.743478  0.796296  0.156863  0.060606  0.569767  0.000000  0.395833   \n",
      "35  0.404348  1.000000  0.411765  0.212121  0.523256  0.360000  0.312500   \n",
      "36  0.308696  0.759259  0.313725  0.136364  1.000000  0.653333  0.333333   \n",
      "37  0.343478  0.407407  0.137255  0.696970  0.325581  0.653333  0.187500   \n",
      "38  0.465217  0.888889  0.000000  0.545455  0.197674  0.093333  0.291667   \n",
      "39  0.178261  0.444444  0.117647  1.000000  0.662791  0.520000  1.000000   \n",
      "\n",
      "          7         8         9   ...        69        70        71        72  \\\n",
      "0   0.043478  0.142857  0.066667  ...  0.000000  0.727273  0.909091  0.363636   \n",
      "1   0.565217  0.028571  0.000000  ...  0.307692  0.818182  0.727273  0.545455   \n",
      "2   0.086957  0.828571  0.022222  ...  0.538462  0.454545  0.545455  0.818182   \n",
      "3   0.043478  0.428571  0.057778  ...  0.846154  0.909091  0.272727  0.818182   \n",
      "4   0.000000  0.057143  0.053333  ...  0.692308  0.818182  0.000000  0.818182   \n",
      "5   0.086957  0.000000  0.248889  ...  0.384615  0.727273  0.090909  0.727273   \n",
      "6   0.086957  0.457143  0.346667  ...  0.076923  0.000000  0.454545  0.454545   \n",
      "7   0.652174  0.228571  0.248889  ...  0.230769  0.090909  0.727273  0.454545   \n",
      "8   0.130435  0.000000  0.395556  ...  0.461538  0.090909  0.636364  0.454545   \n",
      "9   0.217391  0.028571  0.266667  ...  1.000000  0.090909  0.363636  0.363636   \n",
      "10  0.043478  0.114286  0.444444  ...  0.846154  0.181818  0.000000  0.272727   \n",
      "11  0.000000  0.000000  0.537778  ...  0.615385  0.272727  0.090909  0.545455   \n",
      "12  0.043478  0.571429  0.413333  ...  0.000000  0.454545  0.727273  0.727273   \n",
      "13  0.478261  0.114286  0.546667  ...  0.230769  0.363636  0.636364  0.636364   \n",
      "14  0.086957  0.942857  0.848889  ...  0.384615  0.000000  0.909091  0.545455   \n",
      "15  0.086957  0.657143  0.644444  ...  0.692308  0.181818  0.454545  0.272727   \n",
      "16  0.086957  0.542857  0.813333  ...  0.538462  0.363636  0.909091  0.272727   \n",
      "17  0.043478  0.371429  0.920000  ...  0.230769  1.000000  1.000000  0.272727   \n",
      "18  0.043478  0.771429  0.848889  ...  0.384615  0.909091  1.000000  0.454545   \n",
      "19  0.173913  0.000000  0.995556  ...  0.615385  0.818182  0.454545  0.727273   \n",
      "20  0.043478  1.000000  0.688889  ...  0.846154  0.545455  0.272727  1.000000   \n",
      "21  0.000000  0.114286  1.000000  ...  0.538462  0.909091  0.454545  0.636364   \n",
      "22  0.000000  0.085714  0.866667  ...  0.384615  0.818182  0.818182  0.363636   \n",
      "23  0.043478  0.371429  0.844444  ...  0.384615  0.636364  0.454545  0.000000   \n",
      "24  0.130435  0.085714  0.942222  ...  0.846154  0.181818  0.272727  0.181818   \n",
      "25  0.043478  0.057143  0.933333  ...  1.000000  0.545455  0.000000  0.181818   \n",
      "26  0.652174  0.028571  0.871111  ...  0.923077  0.454545  0.090909  0.545455   \n",
      "27  0.608696  0.400000  0.955556  ...  0.384615  0.272727  0.272727  0.636364   \n",
      "28  0.521739  0.400000  0.915556  ...  0.230769  0.090909  0.272727  0.727273   \n",
      "29  0.521739  0.314286  0.822222  ...  0.000000  0.181818  0.272727  0.727273   \n",
      "30  0.826087  0.114286  0.888889  ...  0.461538  0.454545  0.090909  0.181818   \n",
      "31  0.086957  0.400000  0.977778  ...  0.615385  0.363636  0.272727  0.363636   \n",
      "32  0.826087  0.142857  0.853333  ...  0.615385  0.818182  0.363636  0.272727   \n",
      "33  0.695652  0.057143  0.880000  ...  0.230769  0.545455  0.363636  0.363636   \n",
      "34  0.782609  0.142857  0.844444  ...  0.230769  0.363636  0.000000  0.363636   \n",
      "35  1.000000  0.142857  0.906667  ...  0.538462  0.000000  0.000000  0.272727   \n",
      "36  0.130435  0.200000  0.902222  ...  0.615385  0.090909  0.000000  0.454545   \n",
      "37  0.608696  0.142857  0.840000  ...  0.384615  0.000000  0.000000  0.272727   \n",
      "38  0.608696  0.142857  0.800000  ...  0.000000  0.181818  0.272727  0.454545   \n",
      "39  0.521739  0.342857  0.960000  ...  0.384615  0.363636  0.454545  0.454545   \n",
      "\n",
      "          73        74        75        76        77   78  \n",
      "0   0.065574  0.733333  0.666667  0.071429  1.000000  0.5  \n",
      "1   0.098361  1.000000  1.000000  0.000000  0.739130  0.3  \n",
      "2   0.065574  0.866667  0.750000  0.500000  0.304348  0.7  \n",
      "3   0.016393  0.733333  0.583333  0.857143  0.695652  0.6  \n",
      "4   0.000000  0.600000  0.166667  0.928571  0.782609  0.6  \n",
      "5   0.016393  0.466667  0.083333  0.714286  0.521739  0.1  \n",
      "6   0.049180  0.866667  0.166667  0.571429  0.565217  0.2  \n",
      "7   0.032787  0.866667  0.250000  1.000000  0.260870  0.1  \n",
      "8   0.016393  0.733333  0.250000  0.857143  0.304348  0.4  \n",
      "9   0.000000  0.333333  0.583333  0.714286  0.391304  0.2  \n",
      "10  0.032787  0.466667  0.666667  0.214286  0.478261  0.3  \n",
      "11  0.081967  0.533333  0.583333  0.142857  0.608696  0.2  \n",
      "12  0.098361  0.733333  0.416667  0.500000  0.739130  0.1  \n",
      "13  0.114754  0.600000  0.333333  0.642857  0.347826  0.5  \n",
      "14  0.114754  1.000000  0.333333  0.714286  0.000000  0.4  \n",
      "15  0.245902  0.866667  0.166667  0.571429  0.217391  0.4  \n",
      "16  0.311475  0.800000  0.083333  0.500000  0.304348  0.4  \n",
      "17  0.229508  0.466667  0.166667  0.857143  0.173913  0.6  \n",
      "18  0.081967  0.466667  0.333333  0.642857  0.260870  0.6  \n",
      "19  0.016393  0.533333  0.500000  0.571429  0.173913  0.3  \n",
      "20  0.032787  0.933333  0.416667  0.071429  0.304348  0.3  \n",
      "21  0.065574  0.666667  0.416667  0.214286  0.217391  1.0  \n",
      "22  0.049180  0.866667  0.500000  0.357143  0.478261  1.0  \n",
      "23  0.032787  0.533333  0.750000  0.571429  0.478261  0.9  \n",
      "24  0.032787  0.533333  0.583333  0.642857  0.521739  0.2  \n",
      "25  0.114754  0.133333  0.583333  0.500000  0.565217  0.0  \n",
      "26  0.131148  0.133333  0.166667  0.357143  0.478261  0.4  \n",
      "27  0.098361  0.066667  0.083333  0.142857  0.260870  0.3  \n",
      "28  0.114754  0.200000  0.000000  0.071429  0.260870  0.6  \n",
      "29  0.213115  0.000000  0.250000  0.285714  0.347826  0.2  \n",
      "30  0.278689  0.200000  0.333333  0.500000  0.478261  0.3  \n",
      "31  0.213115  0.266667  0.333333  0.500000  0.391304  0.2  \n",
      "32  0.114754  0.600000  0.250000  0.285714  0.391304  0.2  \n",
      "33  0.163934  1.000000  0.500000  0.285714  0.260870  0.0  \n",
      "34  0.311475  1.000000  0.500000  0.357143  0.130435  0.4  \n",
      "35  0.475410  0.800000  0.333333  0.142857  0.173913  0.4  \n",
      "36  0.475410  0.333333  0.000000  0.142857  0.304348  1.0  \n",
      "37  0.295082  0.733333  0.583333  0.214286  0.652174  0.4  \n",
      "38  0.770492  0.666667  0.666667  0.571429  0.652174  0.3  \n",
      "39  1.000000  0.800000  0.583333  0.571429  0.521739  0.2  \n",
      "\n",
      "[40 rows x 79 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\envs\\tens_2gpu\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range=(0,1))\n",
    "df_scaled = sc.fit_transform(data[type])\n",
    "\n",
    "df_scaled = pd.DataFrame(df_scaled)\n",
    "df_scaled.colums = type\n",
    "\n",
    "print(df_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df_scaled[:]\n",
    "test = df_scaled[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(data, label, window_size = 35):\n",
    "    feature_list = []\n",
    "    label_list = []\n",
    "    for i in range(len(data) - window_size):\n",
    "        feature_list.append(np.array(data.iloc[i:i+window_size]))\n",
    "        label_list.append(np.array(label.iloc[i+window_size]))\n",
    "    return np.array(feature_list), np.array(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(79, 40, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15, 1, 30)\n",
      "(15, 10)\n"
     ]
    }
   ],
   "source": [
    "X = np.array(x)\n",
    "y = np.array(b)\n",
    "\n",
    "X = X.reshape(-1, 1, 30)\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential(name=\"PM10_Predict\")\n",
    "\n",
    "model.add(LSTM(10, activation=\"tanh\", input_shape=X.shape[1:]))\n",
    "model.add(Dense(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"PM10_Predict\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 10)                480       \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                110       \n",
      "=================================================================\n",
      "Total params: 590\n",
      "Trainable params: 590\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3392.0747\n",
      "Epoch 2/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3388.8755\n",
      "Epoch 3/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3386.2327\n",
      "Epoch 4/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3383.2385\n",
      "Epoch 5/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3380.1245\n",
      "Epoch 6/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3376.7856\n",
      "Epoch 7/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3372.4099\n",
      "Epoch 8/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3368.1558\n",
      "Epoch 9/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3362.8259\n",
      "Epoch 10/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3356.9214\n",
      "Epoch 11/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3349.4412\n",
      "Epoch 12/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3339.8005\n",
      "Epoch 13/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3326.8984\n",
      "Epoch 14/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3311.3518\n",
      "Epoch 15/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3294.6863\n",
      "Epoch 16/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3281.4233\n",
      "Epoch 17/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3268.7561\n",
      "Epoch 18/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3258.6333\n",
      "Epoch 19/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3248.1829\n",
      "Epoch 20/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3238.0918\n",
      "Epoch 21/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3227.6545\n",
      "Epoch 22/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3217.4753\n",
      "Epoch 23/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3206.7537\n",
      "Epoch 24/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3195.8745\n",
      "Epoch 25/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3186.5300\n",
      "Epoch 26/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3176.6104\n",
      "Epoch 27/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3168.0166\n",
      "Epoch 28/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3159.0562\n",
      "Epoch 29/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3151.3469\n",
      "Epoch 30/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3144.0642\n",
      "Epoch 31/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3134.9192\n",
      "Epoch 32/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3128.2021\n",
      "Epoch 33/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3121.0193\n",
      "Epoch 34/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3113.5962\n",
      "Epoch 35/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3106.6956\n",
      "Epoch 36/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3099.6665\n",
      "Epoch 37/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3093.3506\n",
      "Epoch 38/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3086.1990\n",
      "Epoch 39/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3079.8125\n",
      "Epoch 40/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3073.8193\n",
      "Epoch 41/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3067.4058\n",
      "Epoch 42/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3060.7876\n",
      "Epoch 43/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3054.8354\n",
      "Epoch 44/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3048.2996\n",
      "Epoch 45/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3043.0237\n",
      "Epoch 46/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3036.6807\n",
      "Epoch 47/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3030.5674\n",
      "Epoch 48/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3024.9824\n",
      "Epoch 49/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3019.3325\n",
      "Epoch 50/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3013.7329\n",
      "Epoch 51/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3007.7300\n",
      "Epoch 52/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3002.6562\n",
      "Epoch 53/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2996.6370\n",
      "Epoch 54/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2991.1526\n",
      "Epoch 55/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2985.9160\n",
      "Epoch 56/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2980.2993\n",
      "Epoch 57/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2974.9548\n",
      "Epoch 58/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2969.9097\n",
      "Epoch 59/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2964.6887\n",
      "Epoch 60/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2959.2869\n",
      "Epoch 61/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2954.0293\n",
      "Epoch 62/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2948.9451\n",
      "Epoch 63/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2944.0015\n",
      "Epoch 64/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2938.4485\n",
      "Epoch 65/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2933.8723\n",
      "Epoch 66/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2929.0298\n",
      "Epoch 67/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2923.4050\n",
      "Epoch 68/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2919.0125\n",
      "Epoch 69/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2913.8884\n",
      "Epoch 70/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2909.0171\n",
      "Epoch 71/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2904.7498\n",
      "Epoch 72/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2899.4414\n",
      "Epoch 73/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2894.9441\n",
      "Epoch 74/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2890.0623\n",
      "Epoch 75/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2885.3828\n",
      "Epoch 76/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2880.9131\n",
      "Epoch 77/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2875.9370\n",
      "Epoch 78/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2871.4163\n",
      "Epoch 79/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2867.4102\n",
      "Epoch 80/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2862.0894\n",
      "Epoch 81/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2857.9998\n",
      "Epoch 82/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2853.3254\n",
      "Epoch 83/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2849.1836\n",
      "Epoch 84/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2844.2214\n",
      "Epoch 85/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2840.1562\n",
      "Epoch 86/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2835.9568\n",
      "Epoch 87/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2831.3293\n",
      "Epoch 88/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2827.0691\n",
      "Epoch 89/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2823.0168\n",
      "Epoch 90/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2818.5288\n",
      "Epoch 91/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2814.8047\n",
      "Epoch 92/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2810.2542\n",
      "Epoch 93/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2806.0791\n",
      "Epoch 94/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2801.9695\n",
      "Epoch 95/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2797.8274\n",
      "Epoch 96/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2793.9492\n",
      "Epoch 97/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2790.0056\n",
      "Epoch 98/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 2ms/step - loss: 2785.4546\n",
      "Epoch 99/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2781.8628\n",
      "Epoch 100/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2777.5542\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X, y, epochs=100, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([101.74082 , 161.55037 , 194.15869 , 174.23393 , 159.7075  ,\n",
       "       117.68332 , 115.3068  , 104.95681 , 119.323044,  98.55135 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 54, 162, 233, 184, 174,  96,  74,  82, 110,  44],\n",
       "       [ 38,  33,  40,  60,  51,  62,  49,  30,  56,  32],\n",
       "       [ 51,  57,  18,  15,  14,  27,  22,  13,   6,  12],\n",
       "       [ 14,  22,  26,  29,   6,  16,  11,  48,  38,  68],\n",
       "       [ 48,  45,  54,  28,  52,  48,  89,  31,  20,  60],\n",
       "       [ 50,  37,  50,  39,  20,  47,  69,  69,  27,  59],\n",
       "       [ 31,   7,  20,  19,  20,  16,  17,  10,  15,  49],\n",
       "       [ 20,   3,  20,  17,  19,  24,   4,  15,  15,  13],\n",
       "       [  8,  18,   9,   6,   9,   9,  11,   9,   9,  16],\n",
       "       [224, 244, 216, 222, 214, 228, 227, 213, 204, 240],\n",
       "       [ 61,  40,  53,  62,  22,  41,  32,  24,  46,  26],\n",
       "       [ 61,  40,  53,  62,  22,  41,  32,  24,  46,  26],\n",
       "       [  5,  15,  17,  16,   9,  19,  20,  34,  27,   6],\n",
       "       [ 30,  25,  34,  31,  55,  38,  51,  66,  68,  45],\n",
       "       [ 35,  17,  48,  23,  39,  42,  14,  37,  40,  46]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
